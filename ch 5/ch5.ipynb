{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0+cu121\n",
      "False\n",
      "12.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.version.cuda)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.3\n"
     ]
    }
   ],
   "source": [
    "import torch_geometric\n",
    "print(torch_geometric.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cora Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
      "Processing...\n",
      "Done!\n",
      "/home/consumer/Desktop/advanced-gnn/gnn_venv/lib/python3.10/site-packages/torch_geometric/io/fs.py:215: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Cora()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing the Planetoid dataset\n",
    "from torch_geometric.datasets import Planetoid\n",
    "\n",
    "dataset = Planetoid(root='.', name='Cora')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cora has only one graph we can store in a dedicated variable\n",
    "data = dataset[0]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Cora()\n",
      "--------------------\n",
      "Number of graphs: 1\n",
      "Number of nodes: 2708\n",
      "Number of edges: 10556\n",
      "Number of features: 1433\n",
      "Number of classes: 7\n"
     ]
    }
   ],
   "source": [
    "print(f\"Dataset: {dataset}\")\n",
    "print(\"--------------------\")\n",
    "print(f\"Number of graphs: {len(dataset)}\")\n",
    "print(f\"Number of nodes: {data.x.shape[0]}\")\n",
    "print(f\"Number of edges: {data.edge_index.shape[1]}\")\n",
    "print(f\"Number of features: {dataset.num_features}\")\n",
    "print(f\"Number of classes: {dataset.num_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can also get detailed information from `PyTorch Geometric`'s inbuilt functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph:\n",
      "======\n",
      "Edges are directed: False\n",
      "Has self loops: False\n",
      "Contains isolated nodes: False\n",
      "Contains only one connected component: False\n",
      "Number of training nodes: 140\n",
      "Number of validation nodes: 500\n",
      "Number of test nodes: 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/consumer/Desktop/advanced-gnn/gnn_venv/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'contains_isolated_nodes' is deprecated, use 'has_isolated_nodes' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Graph:\")\n",
    "print(f\"======\")\n",
    "print(f\"Edges are directed: {data.is_directed()}\")\n",
    "print(f\"Has self loops: {data.contains_self_loops()}\")\n",
    "print(f\"Contains isolated nodes: {data.contains_isolated_nodes()}\")\n",
    "print(f\"Contains only one connected component: {data.is_coalesced()}\")\n",
    "print(f\"Number of training nodes: {data.train_mask.sum().item()}\")\n",
    "print(f\"Number of validation nodes: {data.val_mask.sum().item()}\")\n",
    "print(f\"Number of test nodes: {data.test_mask.sum().item()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Facebook Page-Page dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in this dataset, each of the `22,470` nodes represents an official Facebook page. Pages are connected when there are mutual likes between them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Facebook Page-Page dataset is similar to the previous one: it’s a social network with a node classification task. However, there are three major differences with Cora:<br>\n",
    "-The number of nodes is much higher (2,708 versus 22,470)<br>\n",
    "-The dimensionality of the node features decreased dramatically (from 1,433 to 128)<br>\n",
    "-The goal is to classify each node into four categories instead of seven (which is easier since there are fewer options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://graphmining.ai/datasets/ptg/facebook.npz\n",
      "Processing...\n",
      "Done!\n",
      "/home/consumer/Desktop/advanced-gnn/gnn_venv/lib/python3.10/site-packages/torch_geometric/io/fs.py:215: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FacebookPagePage()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_geometric.datasets import FacebookPagePage\n",
    "\n",
    "dataset_fb = FacebookPagePage(root='.')\n",
    "dataset_fb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fb = dataset_fb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: FacebookPagePage()\n",
      "--------------------\n",
      "Number of graphs: 1\n",
      "Number of nodes: 22470\n",
      "Number of edges: 342004\n",
      "Number of features: 128\n",
      "Number of classes: 4\n"
     ]
    }
   ],
   "source": [
    "print(f\"Dataset: {dataset_fb}\")\n",
    "print(\"--------------------\")\n",
    "print(f\"Number of graphs: {len(dataset_fb)}\")\n",
    "print(f\"Number of nodes: {data_fb.x.shape[0]}\")\n",
    "print(f\"Number of edges: {data_fb.edge_index.shape[1]}\")\n",
    "print(f\"Number of features: {dataset_fb.num_features}\")\n",
    "print(f\"Number of classes: {dataset_fb.num_classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph:\n",
      "======\n",
      "Edges are directed: False\n",
      "Has self loops: True\n",
      "Contains isolated nodes: False\n"
     ]
    }
   ],
   "source": [
    "print(f\"Graph:\")\n",
    "print(f\"======\")\n",
    "print(f\"Edges are directed: {data_fb.is_directed()}\")\n",
    "print(f\"Has self loops: {data_fb.contains_self_loops()}\")\n",
    "print(f\"Contains isolated nodes: {data_fb.contains_isolated_nodes()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unlike Cora, FacebookPagePage doesn't have training, evaluation and test masks by default. so we can arbitrarily create masks with the `range()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fb.train_mask = range(18000)\n",
    "data_fb.val_mask = range(18001, 20000)\n",
    "data_fb.test_mask = range(20001, 22470)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying nodes with Vanilla Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike the Zachary's Karate Club dataset, these two datasets contain an additional information: `node features`.<br>\n",
    "They provide additional information about the nodes in a graph, such as a user's age, gender or interests in a social network.<br><br>\n",
    "In a vanilla NN, these embeddings are directly used in the model to perform downstream tasks such as node classification. That means, here we will consider the node features as a regular dataset, <u>without</u> taking into account the topology of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_x = pd.DataFrame(data.x.numpy())\n",
    "df_x['label'] = pd.DataFrame(data.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1424</th>\n",
       "      <th>1425</th>\n",
       "      <th>1426</th>\n",
       "      <th>1427</th>\n",
       "      <th>1428</th>\n",
       "      <th>1429</th>\n",
       "      <th>1430</th>\n",
       "      <th>1431</th>\n",
       "      <th>1432</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1434 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9  ...  1424  1425  1426  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "4  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "\n",
       "   1427  1428  1429  1430  1431  1432  label  \n",
       "0   0.0   0.0   0.0   0.0   0.0   0.0      3  \n",
       "1   0.0   0.0   0.0   0.0   0.0   0.0      4  \n",
       "2   0.0   0.0   0.0   0.0   0.0   0.0      4  \n",
       "3   0.0   0.0   0.0   0.0   0.0   0.0      0  \n",
       "4   0.0   0.0   0.0   0.0   0.0   0.0      3  \n",
       "\n",
       "[5 rows x 1434 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now train a simple Multi-Layer Perceptron (MLP) on `data.x` with the labels provided by `data.y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the necessary libraries\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_pred, y_true):\n",
    "    \"\"\"Calculate accuracy.\"\"\"\n",
    "    return torch.sum(y_pred == y_true) / len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, dim_input, dim_hidden, dim_output):\n",
    "        super().__init__()\n",
    "        self.linear1 = Linear(dim_input, dim_hidden)\n",
    "        self.linear2 = Linear(dim_hidden, dim_output)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.linear2(x)\n",
    "\n",
    "        return F.log_softmax(x, dim = 1)\n",
    "    \n",
    "    def fit(self, data, epochs):\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr = 0.01, weight_decay = 5e-4)\n",
    "\n",
    "        self.train()\n",
    "        for epoch in range(epochs+1):\n",
    "            optimizer.zero_grad()\n",
    "            out = self(data.x)\n",
    "            loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "            acc = accuracy(out[data.train_mask].argmax(dim=1),\n",
    "                          data.y[data.train_mask])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if(epoch % 20 == 0):\n",
    "                val_loss = criterion(out[data.val_mask], data.y[data.val_mask])\n",
    "                val_acc = accuracy(out[data.val_mask].argmax(dim=1),\n",
    "                                  data.y[data.val_mask])\n",
    "                print(f'Epoch {epoch:>3} | Train Loss: {loss:.3f} | Train Acc:'\n",
    "                      f' {acc*100:>5.2f}% | Val Loss: {val_loss:.2f} | '\n",
    "                      f'Val Acc: {val_acc*100:.2f}%')\n",
    "\n",
    "    @torch.no_grad()      \n",
    "    def test(self, data):\n",
    "        self.eval()\n",
    "        out = self(data.x)\n",
    "        acc = accuracy(out.argmax(dim=1)[data.test_mask], data.y[data.test_mask])\n",
    "        return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the MLP on the Cora dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (linear1): Linear(in_features=1433, out_features=16, bias=True)\n",
      "  (linear2): Linear(in_features=16, out_features=7, bias=True)\n",
      ")\n",
      "Epoch   0 | Train Loss: 1.954 | Train Acc: 19.29% | Val Loss: 2.01 | Val Acc: 12.60%\n",
      "Epoch  20 | Train Loss: 0.103 | Train Acc: 100.00% | Val Loss: 1.47 | Val Acc: 50.20%\n",
      "Epoch  40 | Train Loss: 0.013 | Train Acc: 100.00% | Val Loss: 1.60 | Val Acc: 49.40%\n",
      "Epoch  60 | Train Loss: 0.007 | Train Acc: 100.00% | Val Loss: 1.60 | Val Acc: 48.40%\n",
      "Epoch  80 | Train Loss: 0.008 | Train Acc: 100.00% | Val Loss: 1.48 | Val Acc: 50.40%\n",
      "Epoch 100 | Train Loss: 0.009 | Train Acc: 100.00% | Val Loss: 1.42 | Val Acc: 51.40%\n",
      "\n",
      "MLP test accuracy: 51.80%\n"
     ]
    }
   ],
   "source": [
    "# Create MLP model\n",
    "mlp = MLP(dataset.num_features, 16, dataset.num_classes)\n",
    "print(mlp)\n",
    "\n",
    "# Train\n",
    "mlp.fit(data, epochs=100)\n",
    "\n",
    "# Test\n",
    "acc = mlp.test(data)\n",
    "print(f'\\nMLP test accuracy: {acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the MLP on the FacebookPagePage dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (linear1): Linear(in_features=128, out_features=16, bias=True)\n",
      "  (linear2): Linear(in_features=16, out_features=4, bias=True)\n",
      ")\n",
      "Epoch   0 | Train Loss: 1.378 | Train Acc: 26.84% | Val Loss: 1.38 | Val Acc: 27.41%\n",
      "Epoch  20 | Train Loss: 0.642 | Train Acc: 74.93% | Val Loss: 0.67 | Val Acc: 72.84%\n",
      "Epoch  40 | Train Loss: 0.568 | Train Acc: 77.53% | Val Loss: 0.61 | Val Acc: 75.54%\n",
      "Epoch  60 | Train Loss: 0.542 | Train Acc: 78.37% | Val Loss: 0.61 | Val Acc: 75.69%\n",
      "Epoch  80 | Train Loss: 0.525 | Train Acc: 79.16% | Val Loss: 0.60 | Val Acc: 75.94%\n",
      "Epoch 100 | Train Loss: 0.512 | Train Acc: 79.83% | Val Loss: 0.61 | Val Acc: 75.74%\n",
      "\n",
      "MLP test accuracy: 75.46%\n"
     ]
    }
   ],
   "source": [
    "# Create MLP model\n",
    "mlp = MLP(dataset_fb.num_features, 16, dataset_fb.num_classes)\n",
    "print(mlp)\n",
    "\n",
    "# Train\n",
    "mlp.fit(data_fb, epochs=100)\n",
    "\n",
    "# Test\n",
    "acc = mlp.test(data_fb)\n",
    "print(f'\\nMLP test accuracy: {acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we will do the same thing but this time will do it in a graphical architecture, thus, giving birth to the Vanilla Graph Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VanillaGNNLayer(torch.nn.Module):\n",
    "    def __init__(self, dim_input, dim_output):\n",
    "        super().__init__()\n",
    "        self.linear = Linear(dim_input, dim_output, bias = False)\n",
    "\n",
    "    def forward(self, x, adjancy):\n",
    "        x = self.linear(x)\n",
    "        x = torch.sparse.mm(adjancy, x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can create our vanilla GNN, we need to convert the edge index from our dataset (`data.edge_index`) in coordinate format to a dense adjacency matrix. We also need to include `self` loops; otherwise, the central nodes won't be taken into account in their own embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 1., 1.,  ..., 0., 0., 0.],\n",
       "        [0., 1., 1.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 1., 1.],\n",
       "        [0., 0., 0.,  ..., 0., 1., 1.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_geometric.utils import to_dense_adj\n",
    "\n",
    "adjacency = to_dense_adj(data.edge_index)[0]\n",
    "adjacency += torch.eye(len(adjacency))\n",
    "adjacency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# continue from page 80 (103)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
