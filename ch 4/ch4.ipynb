{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import random\n",
    "random.seed(0)\n",
    "import numpy as np\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<networkx.classes.graph.Graph at 0x71e47148a200>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G = nx.erdos_renyi_graph(10, 0.3, seed = 1, directed = False)\n",
    "G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the `next_node` function with the list of our parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_node(previous, current, p, q):\n",
    "    # retrieving the list of neighboring nodes\n",
    "    # from the current node and initialise the list\n",
    "    # of alpha values\n",
    "    neighbors = list(G.neighbors(current))\n",
    "    alphas = []\n",
    "\n",
    "    # for each neighbor, calculate appropriate alpha value ie,\n",
    "    # 1/p -> if neighbor is previous node,\n",
    "    # 1 -> if neighbor is connected to previous node,\n",
    "    # 1/q -> otherwise\n",
    "    for neighbor in neighbors:\n",
    "        if neighbor == previous:\n",
    "            alpha = 1/p\n",
    "        elif G.has_edge(neighbor, previous):\n",
    "            alpha = 1\n",
    "        else:\n",
    "            alpha = 1/q\n",
    "        \n",
    "        alphas.append(alpha)\n",
    "\n",
    "    # now we normalise these values to create probabilities\n",
    "    probs = [alpha / sum(alphas) for alpha in alphas]\n",
    "\n",
    "    # now we randomly select the next node based on the transition\n",
    "    # probabilities calculated in the previous step\n",
    "    next = np.random.choice(neighbors, size=1, p = probs)[0]\n",
    "\n",
    "    return next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "before this function can be tested, we need the code to generate the entire random walk. <br>\n",
    "\n",
    "the next node is chosen by the `next_node()`, which requires additional parameter: `p` and `q`, but also the previous and the current nodes. <br>\n",
    "\n",
    "These nodes can be easily obtained by looking at the two last elements added to the `walk` variable. We also return strings instead of integers for compatibility reasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# updated version of the random_walk() method\n",
    "def random_walk(start, length, p, q):\n",
    "    walk = [start]\n",
    "\n",
    "    for i in range(length):\n",
    "        current = walk[-1]\n",
    "        previous = walk[-2] if len(walk) > 1 else None\n",
    "        next = next_node(previous, current, p, q)\n",
    "        walk.append(next)\n",
    "    \n",
    "    return [str(x) for x in walk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0', '4', '7', '6', '4', '5', '4', '5', '6']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_walk(0, 8, p = 1, q = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now, let's bias them toward going back to the previous node with `q = 10`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0', '9', '1', '9', '1', '9', '1', '0', '1']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_walk(0, 8, p = 1, q = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time, the random walk explores more nodes in the graph. You can see that it never goes back to the previous node because the probability is low with `p = 10`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0', '1', '9', '4', '7', '8', '7', '4', '6']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_walk(0, 8, p = 10, q = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the dataset - Zachary's Karate club\n",
    "G = nx.karate_club_graph()\n",
    "\n",
    "# transforming the nodes' labels into numerical values (0 and 1):\n",
    "labels = []\n",
    "for node in G.nodes:\n",
    "    label = G.nodes[node]['club']\n",
    "    labels.append(1 if label == 'Officer' else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we generate a list of random walks as seen previously using our `random_walk()` method 80 times for each node in the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "walks = []\n",
    "\n",
    "for node in G.nodes:\n",
    "    for _ in range(80):\n",
    "        walks.append(random_walk(node, 10, 3, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating an instance of Word2Vec (a skip gram model) with a hierarchical `softmax` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "node2vec = Word2Vec(walks,\n",
    "                    hs = 1, # hierarchical softmax\n",
    "                    sg = 1, # skip-gram,\n",
    "                    vector_size = 100,\n",
    "                    window = 10,\n",
    "                    workers = 2,\n",
    "                    min_count = 1,\n",
    "                    seed = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The skip gram model is now trained on the sequences we generated for 30 epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(185807, 897600)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node2vec.train(walks, total_examples = node2vec.corpus_count, epochs = 30, report_delay = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we now craete masks to train and test the classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask = [2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24]\n",
    "train_mask_str = [str(x) for x in train_mask]\n",
    "test_mask = [0, 1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21,\n",
    "23, 25, 26, 27, 28, 29, 30, 31, 32, 33]\n",
    "test_mask_str = [str(x) for x in test_mask]\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random forest classifier is trained on the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(random_state=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(random_state = 0)\n",
    "clf.fit(node2vec.wv[train_mask_str], labels[train_mask]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now evaluate it in terms of accuracy for the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node2Vec accuracy = 90.91%\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(node2vec.wv[test_mask_str])\n",
    "acc = accuracy_score(y_pred, labels[test_mask])\n",
    "print(f\"Node2Vec accuracy = {acc * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a movie `RecSys`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most popular applications of GNNs is Recommendation System. If you think about it, the goal is to produce vectors (in this case, the name of the movies) with the ability to measure their similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideally we would want to create [biased] random walks of movies, which requires a graph dataset where similar movies are connected to each other. This is not easy to find."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Here, we will try to implement a simple and intuitive approach: movies that are liked by the same users are connected. We will then use this graph to learn movie embeddings using Node2Vec.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "from urllib.request import urlopen\n",
    "from zipfile import ZipFile\n",
    "\n",
    "url = 'https://files.grouplens.org/datasets/movielens/ml-100k.zip'\n",
    "\n",
    "with urlopen(url) as zurl:\n",
    "    with ZipFile(BytesIO(zurl.read())) as zfile:\n",
    "        zfile.extractall('.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we are interested in two files: `ratings.csv` and `movies.csv`. The first one stores all the rating made by users, and the second one allows us to translate movie identifiers into titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>unix_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>880</td>\n",
       "      <td>476</td>\n",
       "      <td>3</td>\n",
       "      <td>880175444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>716</td>\n",
       "      <td>204</td>\n",
       "      <td>5</td>\n",
       "      <td>879795543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>276</td>\n",
       "      <td>1090</td>\n",
       "      <td>1</td>\n",
       "      <td>874795795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>13</td>\n",
       "      <td>225</td>\n",
       "      <td>2</td>\n",
       "      <td>882399156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>12</td>\n",
       "      <td>203</td>\n",
       "      <td>3</td>\n",
       "      <td>879959583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id  movie_id  rating  unix_timestamp\n",
       "0          196       242       3       881250949\n",
       "1          186       302       3       891717742\n",
       "2           22       377       1       878887116\n",
       "3          244        51       2       880606923\n",
       "4          166       346       1       886397596\n",
       "...        ...       ...     ...             ...\n",
       "99995      880       476       3       880175444\n",
       "99996      716       204       5       879795543\n",
       "99997      276      1090       1       874795795\n",
       "99998       13       225       2       882399156\n",
       "99999       12       203       3       879959583\n",
       "\n",
       "[100000 rows x 4 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ratings = pd.read_csv('ml-100k/u.data', sep = '\\t', names = ['user_id', 'movie_id', 'rating', 'unix_timestamp'])\n",
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>GoldenEye (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Four Rooms (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Get Shorty (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Copycat (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1677</th>\n",
       "      <td>1678</td>\n",
       "      <td>Mat' i syn (1997)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1678</th>\n",
       "      <td>1679</td>\n",
       "      <td>B. Monkey (1998)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1679</th>\n",
       "      <td>1680</td>\n",
       "      <td>Sliding Doors (1998)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1680</th>\n",
       "      <td>1681</td>\n",
       "      <td>You So Crazy (1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1681</th>\n",
       "      <td>1682</td>\n",
       "      <td>Scream of Stone (Schrei aus Stein) (1991)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1682 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      movie_id                                      title\n",
       "0            1                           Toy Story (1995)\n",
       "1            2                           GoldenEye (1995)\n",
       "2            3                          Four Rooms (1995)\n",
       "3            4                          Get Shorty (1995)\n",
       "4            5                             Copycat (1995)\n",
       "...        ...                                        ...\n",
       "1677      1678                          Mat' i syn (1997)\n",
       "1678      1679                           B. Monkey (1998)\n",
       "1679      1680                       Sliding Doors (1998)\n",
       "1680      1681                        You So Crazy (1994)\n",
       "1681      1682  Scream of Stone (Schrei aus Stein) (1991)\n",
       "\n",
       "[1682 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing the movie dataset\n",
    "movies = pd.read_csv('ml-100k/u.item', sep = '|', usecols = range(2), names = ['movie_id', 'title'], encoding = 'latin-1')\n",
    "movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we would want to see all movies liked by the same user. This means that ratings such as 1, 2, and 3 and not very relevant. So, we only keep ratings 4 and 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>unix_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>298</td>\n",
       "      <td>474</td>\n",
       "      <td>4</td>\n",
       "      <td>884182806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>253</td>\n",
       "      <td>465</td>\n",
       "      <td>5</td>\n",
       "      <td>891628467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>286</td>\n",
       "      <td>1014</td>\n",
       "      <td>5</td>\n",
       "      <td>879781125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>200</td>\n",
       "      <td>222</td>\n",
       "      <td>5</td>\n",
       "      <td>876042340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>122</td>\n",
       "      <td>387</td>\n",
       "      <td>5</td>\n",
       "      <td>879270459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99988</th>\n",
       "      <td>421</td>\n",
       "      <td>498</td>\n",
       "      <td>4</td>\n",
       "      <td>892241344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99989</th>\n",
       "      <td>495</td>\n",
       "      <td>1091</td>\n",
       "      <td>4</td>\n",
       "      <td>888637503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99990</th>\n",
       "      <td>806</td>\n",
       "      <td>421</td>\n",
       "      <td>4</td>\n",
       "      <td>882388897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99991</th>\n",
       "      <td>676</td>\n",
       "      <td>538</td>\n",
       "      <td>4</td>\n",
       "      <td>892685437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>716</td>\n",
       "      <td>204</td>\n",
       "      <td>5</td>\n",
       "      <td>879795543</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>55375 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id  movie_id  rating  unix_timestamp\n",
       "5          298       474       4       884182806\n",
       "7          253       465       5       891628467\n",
       "11         286      1014       5       879781125\n",
       "12         200       222       5       876042340\n",
       "16         122       387       5       879270459\n",
       "...        ...       ...     ...             ...\n",
       "99988      421       498       4       892241344\n",
       "99989      495      1091       4       888637503\n",
       "99990      806       421       4       882388897\n",
       "99991      676       538       4       892685437\n",
       "99996      716       204       5       879795543\n",
       "\n",
       "[55375 rows x 4 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = ratings[ratings['rating'] >= 4]\n",
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique users with 4 and 5 ratings: 942\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of unique users with 4 and 5 ratings: {ratings['user_id'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to count every time that two movies are liked by the same user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "pairs = defaultdict(int)\n",
    "\n",
    "# loop through the entire list of users\n",
    "for group in ratings.groupby('user_id'):\n",
    "    # list of IDs of movies rated by the current user\n",
    "    user_movies = list(group[1][\"movie_id\"])\n",
    "\n",
    "    # count every time two movies are seen together\n",
    "    for i in range(len(user_movies)):\n",
    "        for j in range(i + 1, len(user_movies)):\n",
    "            pairs[(user_movies[i], user_movies[j])] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pairs` object now stores the number of times two movies have been liked by the same user. We can use this information to build the edges of our graph as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of graph nodes: 410\n",
      "Total number of graph edges: 14936\n"
     ]
    }
   ],
   "source": [
    "G = nx.Graph()\n",
    "\n",
    "# for each pair, we unpack the two movies and their corresponding score\n",
    "for pair in pairs:\n",
    "    movie1, movie2 = pair\n",
    "    score = pairs[pair]\n",
    "\n",
    "    # the edge is only created when the score is high enough\n",
    "    if score >= 20:\n",
    "        G.add_edge(movie1, movie2, weight = score)\n",
    "\n",
    "print(f\"Total number of graph nodes: {G.number_of_nodes()}\")\n",
    "print(f\"Total number of graph edges: {G.number_of_edges()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/consumer/Desktop/advanced-gnn/gnn_venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Computing transition probabilities: 100%|██████████| 410/410 [00:06<00:00, 60.07it/s] \n",
      "Generating walks (CPU: 1): 100%|██████████| 200/200 [00:19<00:00, 10.45it/s]\n"
     ]
    }
   ],
   "source": [
    "from node2vec import Node2Vec\n",
    "\n",
    "node2vec = Node2Vec(G, dimensions = 64, walk_length = 20, num_walks = 200, p = 2, q = 1, workers = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we now train a model on these biased random walks with a window of 10 (5 nodes before, 5 nodes after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = node2vec.fit(window = 10, min_count = 1, batch_words = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Return of the Jedi (1983): 0.61\n",
      "Raiders of the Lost Ark (1981): 0.55\n",
      "Godfather, The (1972): 0.49\n",
      "Indiana Jones and the Last Crusade (1989): 0.46\n",
      "White Squall (1996): 0.44\n"
     ]
    }
   ],
   "source": [
    "def recommend(movie):\n",
    "    \"\"\"method to recommend movies based on a given title\"\"\"\n",
    "    movie_id = str(movies[movies['title'] == movie].movie_id.values[0])\n",
    "    for id in model.wv.most_similar(movie_id)[: 5]:\n",
    "        title = movies[movies['movie_id'] == int(id[0])].title.values[0]\n",
    "        print(f\"{title}: {id[1]:.2f}\")\n",
    "\n",
    "recommend(\"Star Wars (1977)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model tells us that Return of the Jedi and Raiders of the Lost Ark are the most similar to Star Wars, although with a relatively low score (`< 0.7`). Nonetheless, this is a good result for our first step into the RecSys world! In later chapters, we’ll see more powerful models and approaches to building state-of-the-art RecSys."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
